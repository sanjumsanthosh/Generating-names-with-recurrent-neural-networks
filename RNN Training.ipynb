{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(os.getcwd(),'..','dataset','Names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_characters = set()\n",
    "for indx,name in enumerate(dataset['Name']):\n",
    "    try:\n",
    "        for c in name:\n",
    "            unique_characters.add(c)\n",
    "    except:pass\n",
    "unique_characters = {k:v for v,k in enumerate(unique_characters)}\n",
    "unique_characters[' ']=len(unique_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def char_to_index(character):\n",
    "    indx = unique_characters.get(character,-1)\n",
    "    assert indx!=-1 , \"Value not in unique characters\"\n",
    "    return indx\n",
    "\n",
    "def word_to_tensor(word):\n",
    "    tensor = torch.zeros(len(word) , 1 , len(unique_characters))\n",
    "    for line_indx,char in enumerate(word):\n",
    "        tensor[line_indx][0][char_to_index(char)] = 1\n",
    "    return tensor\n",
    "\n",
    "def tensor_to_word(tensor):\n",
    "    word = ''\n",
    "     \n",
    "    for v in tensor_to_index(tensor.detach()):\n",
    "        word+=list(unique_characters.keys())[int(v)]\n",
    "    return word\n",
    "\n",
    "def tensor_to_index(tensor):\n",
    "    return torch.argmax(tensor,dim=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self , h_out_size):\n",
    "        \n",
    "        super(RNN,self).__init__()\n",
    "        self.h_out_size = h_out_size\n",
    "        \n",
    "        self.h_out = nn.Linear(len(unique_characters)+h_out_size , h_out_size)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(h_out_size, len(unique_characters)),\n",
    "            nn.Softmax(dim=2)\n",
    "        )\n",
    "    \n",
    "    def forward(self,input_tensor,h_prev):\n",
    "        \n",
    "        input_tensor = torch.cat((input_tensor,h_prev),dim=2)\n",
    "        out_h = self.h_out(input_tensor)\n",
    "        out_val = self.output(out_h)\n",
    "        return out_h,out_val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_input \n",
    "h_out_size_const = 64\n",
    "t = word_to_tensor('sam')\n",
    "h_start = torch.zeros(t.shape[0],t.shape[1],h_out_size_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(h_out_size_const)\n",
    "out_h,out_val = rnn(t,h_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rnn = RNN(h_out_size_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(Rnn.parameters(),lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word(word):\n",
    "    tensor_word = word_to_tensor(word)\n",
    "    h = torch.zeros(len(word),1,h_out_size_const)\n",
    "    h,out_val = Rnn(tensor_word,h)\n",
    "    return out_val,tensor_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_loss(out_tensor,act_tensor):\n",
    "    act_tensor = torch.cat((act_tensor[1:],word_to_tensor(' ')))\n",
    "    loss = loss_fn(out_tensor.squeeze() , tensor_to_index(act_tensor).squeeze())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3575)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_loss(word_to_tensor('am '),word_to_tensor('sam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1398)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn(torch.Tensor([[0.5,0.3,0.2]]),torch.Tensor([1]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 1 of 5 with loss 3.2192375113616043\n",
      "tensor([[[2.0701e-24, 1.8453e-18, 7.3216e-25, 5.1106e-21, 8.6041e-27,\n",
      "          2.6040e-21, 5.0477e-24, 9.3272e-22, 2.1269e-23, 1.0898e-23,\n",
      "          5.8424e-24, 6.2778e-19, 2.9699e-30, 1.0000e+00, 2.6594e-22,\n",
      "          1.0409e-24, 3.9180e-26, 1.4465e-27, 1.1167e-22, 2.6365e-21,\n",
      "          3.6701e-29, 3.0439e-15, 7.9552e-30, 1.0363e-15, 1.7152e-25,\n",
      "          2.9051e-21, 3.6215e-29]],\n",
      "\n",
      "        [[2.0921e-28, 1.0770e-22, 1.4515e-29, 1.2298e-24, 5.3235e-33,\n",
      "          1.5554e-27, 1.6453e-35, 2.4238e-24, 5.0955e-27, 1.0678e-25,\n",
      "          1.5904e-26, 1.0000e+00, 6.5188e-36, 6.0183e-20, 5.2259e-24,\n",
      "          1.2318e-23, 2.3952e-33, 9.3789e-35, 2.9496e-26, 2.0321e-24,\n",
      "          1.8852e-38, 1.7135e-12, 1.1891e-39, 5.5071e-17, 1.9562e-29,\n",
      "          2.9538e-26, 4.9131e-39]],\n",
      "\n",
      "        [[9.1178e-19, 1.7509e-13, 4.1757e-19, 3.4519e-15, 8.4525e-21,\n",
      "          1.9017e-16, 1.9396e-20, 1.4825e-15, 9.5468e-18, 6.8793e-18,\n",
      "          2.4547e-17, 4.6174e-08, 4.2557e-23, 1.0000e+00, 1.0729e-15,\n",
      "          4.8177e-18, 3.3279e-20, 1.7093e-21, 8.3894e-17, 2.5122e-15,\n",
      "          3.3864e-23, 1.8827e-10, 1.7118e-23, 4.7103e-11, 2.2763e-19,\n",
      "          5.7952e-16, 2.6730e-23]],\n",
      "\n",
      "        [[8.8468e-13, 8.1883e-12, 4.6780e-13, 4.2198e-09, 2.7731e-12,\n",
      "          3.1448e-12, 6.7296e-13, 6.5475e-11, 5.5453e-11, 1.5410e-13,\n",
      "          7.1486e-12, 1.0000e+00, 2.6015e-11, 1.2618e-07, 1.2466e-10,\n",
      "          4.8130e-12, 3.1915e-12, 5.2853e-12, 4.4251e-11, 1.4610e-08,\n",
      "          2.1001e-11, 1.0741e-15, 3.7580e-11, 8.7944e-11, 1.1175e-12,\n",
      "          2.6090e-10, 6.9308e-08]],\n",
      "\n",
      "        [[2.0701e-24, 1.8453e-18, 7.3216e-25, 5.1106e-21, 8.6041e-27,\n",
      "          2.6040e-21, 5.0477e-24, 9.3272e-22, 2.1269e-23, 1.0898e-23,\n",
      "          5.8424e-24, 6.2778e-19, 2.9699e-30, 1.0000e+00, 2.6594e-22,\n",
      "          1.0409e-24, 3.9180e-26, 1.4465e-27, 1.1167e-22, 2.6365e-21,\n",
      "          3.6701e-29, 3.0439e-15, 7.9552e-30, 1.0363e-15, 1.7152e-25,\n",
      "          2.9051e-21, 3.6215e-29]]], grad_fn=<SoftmaxBackward>)\n",
      "Completed epoch 2 of 5 with loss 3.202155104223287\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          8.1457e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5927e-12, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          8.1457e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5927e-12, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]]], grad_fn=<SoftmaxBackward>)\n",
      "Completed epoch 3 of 5 with loss 3.194048874891582\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          6.1895e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2683e-12, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          6.1895e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2683e-12, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]]], grad_fn=<SoftmaxBackward>)\n",
      "Completed epoch 4 of 5 with loss 3.1899957602257287\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          3.5873e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2718e-13, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          3.5873e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2718e-13, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]]], grad_fn=<SoftmaxBackward>)\n",
      "Completed epoch 5 of 5 with loss 3.187563891426217\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          2.5994e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8125e-13, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          2.5994e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8125e-13, 0.0000e+00,\n",
      "          0.0000e+00, 1.0000e+00]]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "loss_acc = []\n",
    "for epoc in range(1, epochs + 1):\n",
    "\n",
    "    for indx, name in enumerate(dataset['Name']):\n",
    "        optimizer.zero_grad()\n",
    "        if (type(name) != str): continue\n",
    "        out, act_tensor = train_word(name)\n",
    "        loss = find_loss(out, act_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_acc.append(loss.item())\n",
    "\n",
    "    print('Completed epoch {} of {} with loss {}'.format(\n",
    "        epoc, epochs, np.mean(np.array(loss_acc))))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out,act_tensor = train_word(dataset['Name'][2])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondad8fd5e04a2b041c7b6f9746d4c295a87"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
